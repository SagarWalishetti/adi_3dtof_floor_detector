/******************************************************************************
Copyright (c), 2023 - Analog Devices Inc. All Rights Reserved.
This software is PROPRIETARY & CONFIDENTIAL to Analog Devices, Inc.
and its licensors.
******************************************************************************/

#include "adi_3dtof_floor_detector_node.h"
#include "adtf31xx_sensor_frame_info.h"
#include "module_profile.h"

/**
 * @brief Updates the parameters of algorithm based on dynamic reconfigure.
 *
 */

void ADI3DToFFloorDetector::updateDynamicReconfigureVariablesProcessThread()
{
  if (enable_ransac_floor_detection_ != dynamic_reconf_params_.enable_ransac_floor_detection) {
    enable_ransac_floor_detection_ = dynamic_reconf_params_.enable_ransac_floor_detection;
    RCLCPP_INFO(
      this->get_logger(),
      "Dynamic Reconfigure: Modified the 'enable_ransac_floor_detection' parameter %d",
      enable_ransac_floor_detection_);
  }

  if (ransac_max_iterations_ != dynamic_reconf_params_.ransac_max_iterations) {
    ransac_max_iterations_ = dynamic_reconf_params_.ransac_max_iterations;
    floor_plane_detection_->setMaxIterations(ransac_max_iterations_);
    RCLCPP_INFO(
      this->get_logger(), "Dynamic Reconfigure: Modified the 'ransac_max_iterations' parameter %d",
      ransac_max_iterations_);
  }

  if (ransac_distance_threshold_mtr_ != dynamic_reconf_params_.ransac_distance_threshold_mtr) {
    ransac_distance_threshold_mtr_ = dynamic_reconf_params_.ransac_distance_threshold_mtr;
    floor_plane_detection_->setRANSACDistanceThreshold(ransac_distance_threshold_mtr_);
    RCLCPP_INFO(
      this->get_logger(),
      "Dynamic Reconfigure: Modified the 'ransac_distance_threshold_mtr' parameter %f",
      ransac_distance_threshold_mtr_);
  }

  if (enable_fallback_floor_detection_ != dynamic_reconf_params_.enable_fallback_floor_detection) {
    enable_fallback_floor_detection_ = dynamic_reconf_params_.enable_fallback_floor_detection;
    RCLCPP_INFO(
      this->get_logger(),
      "Dynamic Reconfigure: Modified the 'enable_fallback_floor_detection' parameter %d",
      enable_fallback_floor_detection_);
  }

  if (
    fallback_floor_height_offset_mtr_ != dynamic_reconf_params_.fallback_floor_height_offset_mtr) {
    fallback_floor_height_offset_mtr_ = dynamic_reconf_params_.fallback_floor_height_offset_mtr;
    floor_distance_threshold_mm_ = (camera_height_mtr_ - fallback_floor_height_offset_mtr_) * 1000.0f;
    RCLCPP_INFO(
      this->get_logger(),
      "Dynamic Reconfigure: Modified the 'fallback_floor_height_offset_mtr' parameter %f",
      fallback_floor_height_offset_mtr_);
  }
}

/**
 *
 * @brief This function is the entry point to the adi 3d tof floor detector algorithm
 *
 *
 */
bool ADI3DToFFloorDetector::runFloorDetection()
{
  PROFILE_FUNCTION_START(FLOOR_DETECTOR_0)

  PROFILE_FUNCTION_START(FLOOR_DETECTOR_1_PREPROCESS)
  // nullptr checks
  if ((camera_map_tf_listener_ == nullptr) || (optical_map_tf_listener_ == nullptr)) {
    return false;
  }

  // Update dynamic reconfigure values.
  updateDynamicReconfigureVariablesProcessThread();

  // Get frame from sensor.
  ADTF31xxSensorFrameInfo * inframe = nullptr;
  try {
    inframe = floorDetectorIOThreadGetNextFrame();
  } catch (const std::exception & e) {
    std::cerr << e.what() << '\n';
  }

  if (inframe == nullptr) {
    return false;
  }

  depth_frame_ = inframe->getDepthFrame();
  ir_frame_ = inframe->getIRFrame();
  xyz_frame_ = inframe->getXYZFrame();
  compressed_depth_frame_ = inframe->getCompressedDepthFrame();
  compressed_depth_frame_size_ = inframe->getCompressedDepthFrameSize();

  if (
    (depth_frame_ == nullptr) || (ir_frame_ == nullptr) || (xyz_frame_ == nullptr) ||
    ((enable_compression_op_image_topics_) && (compressed_depth_frame_ == nullptr))) {
    return false;
  }

  // Rotation of point cloud
  if (camera_tilted_) {
    // With Rotation
    input_xyz_frame_ = inframe->getRotatedXYZFrame();
  } else {
    // Without Rotation
    input_xyz_frame_ = xyz_frame_;
  }
  // xyz_frame is getting published (Rviz will handle rotation for this point cloud for visualization)
  output_xyz_frame_ = xyz_frame_;

  PROFILE_FUNCTION_END(FLOOR_DETECTOR_1_PREPROCESS)

  PROFILE_FUNCTION_START(FLOOR_DETECTOR_6_RUN)
  // Set global timestamp
  curr_frame_timestamp_ = inframe->getFrameTimestamp();

  ADI3DToFFloorDetectorOutputInfo * new_output_frame =
    new ADI3DToFFloorDetectorOutputInfo(image_width_, image_height_);
  if (new_output_frame == nullptr) {
    return false;
  }

  // nullptr checks
  if (
    (new_output_frame->depth_frame_ == nullptr) || (new_output_frame->ir_frame_ == nullptr) ||
    (new_output_frame->xyz_frame_ == nullptr)) {
    return false;
  }

  // Set default values for floor mask
  memset(floor_mask_, 0, (image_width_ * image_height_ * sizeof(floor_mask_[0])));
  if (enable_compression_op_image_topics_) {
    memset(
      compressed_floor_mask_, 0, (compressed_floor_pixels_ * sizeof(compressed_floor_mask_[0])));
  }

  // Set filter flag
  FilterFlag filter_flag = DoNotRemoveFloor;
  if (enable_ransac_floor_detection_) {
    PROFILE_FUNCTION_START(FLOOR_DETECTOR_7_RANSAC_RUN)
    // int64 e1 = cv::getTickCount();
    // Floor Removal using modified PCL RANSAC
    // Default values for Enhanced RANSAC debug outputs
    ransac_iterations_ = 0;
    noise_count_ = 0;
    ransac_time_ms_ = 0;

    // Enhanced RANSAC approach
    ransac_floor_detection_status_ = floor_plane_detection_->detectFloorUsingEnhancedRANSAC(
      &depth_frame_[0], &output_xyz_frame_[0], filter_flag, &floor_mask_[0],
      &compressed_floor_mask_[0], input_xyz_frame_, inframe->getModifiedXYZFrame(),
      inframe->getModifiedXYZFrameSize(), inframe->getNearbyObjectsFoundFlag());

#if 0
    //Debug outputs   
    if (ransac_floor_detection_status_)
    {
      ransac_iterations_ = floor_plane_detection_->getRANSACIterations();
      noise_count_ = floor_plane_detection_->getNoiseCount();
    }
#endif
    // int64 e2 = cv::getTickCount();
    // ransac_time_ms_ = ((e2 - e1) * 1000.0f) / cv::getTickFrequency();

    PROFILE_FUNCTION_END(FLOOR_DETECTOR_7_RANSAC_RUN)
  }

  if (
    ((!ransac_floor_detection_status_) && (enable_fallback_floor_detection_)) ||
    (!enable_ransac_floor_detection_)) {
    PROFILE_FUNCTION_START(FLOOR_DETECTOR_8_FALLBACK_RUN)
    if (!ransac_floor_detection_status_) {
      std::cout << "Running traditional floor detection algorithm.\n" << std::endl;
    }
    // 3D Y Threshold based approach
    image_proc_utils_->detectFloorFromPointCloud(
      input_xyz_frame_, floor_distance_threshold_mm_, image_width_, image_height_, depth_frame_,
      output_xyz_frame_, filter_flag, &floor_mask_[0], &compressed_floor_mask_[0]);
    PROFILE_FUNCTION_END(FLOOR_DETECTOR_8_FALLBACK_RUN)
  }

  // The generate visualization and publish topics are run in a different thread,
  // so, copy the buffers needed by these functions to a queue
  if (new_output_frame != nullptr) {
    new_output_frame->frame_number_ = frame_number_;
    new_output_frame->ransac_floor_detection_status_ = ransac_floor_detection_status_;
    new_output_frame->ransac_iterations_ = ransac_iterations_;
    new_output_frame->noise_count_ = noise_count_;
    new_output_frame->ransac_time_ms_ = ransac_time_ms_;

    //IR compression is happening in output thread
    memcpy(
      new_output_frame->ir_frame_, ir_frame_, image_width_ * image_height_ * sizeof(ir_frame_[0]));

    if (enable_pointcloud_publisher_) {
      memcpy(
        new_output_frame->xyz_frame_, input_xyz_frame_,
        3 * image_width_ * image_height_ * sizeof(xyz_frame_[0]));
    }

    if (enable_compression_op_image_topics_) {
      new_output_frame->compressed_depth_frame_size_ = compressed_depth_frame_size_;
      new_output_frame->compressed_floor_mask_size_ = compressed_floor_pixels_;
      memcpy(
        new_output_frame->compressed_depth_frame_, compressed_depth_frame_,
        2 * image_width_ * image_height_ * sizeof(compressed_depth_frame_[0]));
      memcpy(
        new_output_frame->compressed_floor_mask_, compressed_floor_mask_,
        compressed_floor_pixels_ * sizeof(compressed_floor_mask_[0]));
    } else {
      memcpy(
        new_output_frame->depth_frame_, depth_frame_,
        image_width_ * image_height_ * sizeof(depth_frame_[0]));
      memcpy(
        new_output_frame->floor_mask_8bit_, floor_mask_,
        image_width_ * image_height_ * sizeof(floor_mask_[0]));
    }

    // Push
    floorDetectorIOThreadPushOutputNode(new_output_frame);
  }

  frame_number_++;

  // dispose the frame
  delete inframe;
  PROFILE_FUNCTION_END(FLOOR_DETECTOR_6_RUN)

  PROFILE_FUNCTION_END(FLOOR_DETECTOR_0)
  return true;
}

/**
 * @brief This function gives TF between different camera frames
 *
 */
void ADI3DToFFloorDetector::getCameraLinksTF()
{
  // Get RPY
  geometry_msgs::msg::TransformStamped camera_map_transform;
  try {
    camera_map_transform = camera_map_tf_buffer_->lookupTransform(
      "map", camera_link_, rclcpp::Time(0.0f), rclcpp::Duration(5, 0));
  } catch (tf2::TransformException & ex) {
    RCLCPP_ERROR(this->get_logger(), "Camera to Map TF2 Error: %s\n", ex.what());
    return;
  }

  // Camera Tilt
  // Ref : https://en.wikipedia.org/wiki/Rotation_matrix
  tf2::Quaternion camera_map_qt(
    camera_map_transform.transform.rotation.x, camera_map_transform.transform.rotation.y,
    camera_map_transform.transform.rotation.z, camera_map_transform.transform.rotation.w);
  tf2::Matrix3x3 camera_map_rotation_matrix(camera_map_qt);
  double roll, pitch, yaw;
  /*
  Input Pitch should be always in (-1.57, 1.57).
  For the |pitch| > 1.57, please consider taking (3.14 +/- pitch) as output here.
  For input pitch |1.57|, output will be  wrong because cosÎ² = 0
  */
  camera_map_rotation_matrix.getRPY(roll, pitch, yaw);
  camera_roll_rad_ = roll;
  camera_pitch_rad_ = pitch;
  camera_yaw_rad_ = yaw;

  camera_tilted_ = false;

  // Yaw is neglected as it does not affect the algorithm
  if (
    (std::fabs(camera_roll_rad_) >= std::numeric_limits<float>::epsilon()) ||
    (std::fabs(camera_pitch_rad_) >= std::numeric_limits<float>::epsilon())) {
    camera_tilted_ = true;
  }

  // Get reverse rotation matrix
  geometry_msgs::msg::TransformStamped optical_map_transform;
  try {
    optical_map_transform = optical_map_tf_buffer_->lookupTransform(
      "map", optical_camera_link_, rclcpp::Time(0.0f), rclcpp::Duration(5, 0));
  } catch (tf2::TransformException & ex) {
    RCLCPP_ERROR(this->get_logger(), "Optical to Map TF2 Error: %s\n", ex.what());
    return;
  }

  tf2::Quaternion optical_map_qt(
    optical_map_transform.transform.rotation.x, optical_map_transform.transform.rotation.y,
    optical_map_transform.transform.rotation.z, optical_map_transform.transform.rotation.w);
  tf2::Matrix3x3 cam_rotation_matrix(optical_map_qt);

  depth_extrinsics_external_.translation_matrix[0] = optical_map_transform.transform.translation.x;
  depth_extrinsics_external_.translation_matrix[1] = optical_map_transform.transform.translation.y;
  depth_extrinsics_external_.translation_matrix[2] = optical_map_transform.transform.translation.z;

  // Rotation Matrix
  float optical_map_rotation_matrix[9];
  int j = 0;
  for (int i = 0; i < 3; i++) {
    for (int k = 0; k < 3; k++) {
      optical_map_rotation_matrix[j++] = cam_rotation_matrix.getRow(i)[k];
    }
  }

  // Point Cloud reference : forward -> +Z, Right -> +X, Down -> +Y
  // ROS reference : forward -> +X, Left -> +Y, Up -> +Z
  // Multiplying with constant matrix which rotates the point cloud in Z -90 and X -90 degrees
  // Final Rotation Matrix = reference_reverse_rotation_matrix * optical_map_rotation_matrix
  float reference_reverse_rotation_matrix[9] = {0, -1, 0, 0, 0, -1, 1, 0, 0};
  image_proc_utils_->matrixMultiplication(
    &reference_reverse_rotation_matrix[0], 3, 3, &optical_map_rotation_matrix[0], 3, 3,
    &depth_extrinsics_external_.rotation_matrix[0]);

  /*Camera height from floor*/
  camera_height_mtr_ = optical_map_transform.transform.translation.z;
  floor_distance_threshold_mm_ = (camera_height_mtr_ - fallback_floor_height_offset_mtr_) * 1000.0f;
}
